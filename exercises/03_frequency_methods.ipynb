{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNK4OichEYLN",
    "outputId": "9a45c593-58f6-4818-ccbe-59f8576610a3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term-Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8464/3895389962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m df = pd.DataFrame(X.T.todense(),\n\u001b[1;32m---> 10\u001b[1;33m                   \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                   columns=[n for n in documents])\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "documents = [\"This is the first document.\",\n",
    "             \"This document is the second document.\",\n",
    "             \"And this is the third one.\",\n",
    "             \"Is this the first document?\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "df = pd.DataFrame(X.T.todense(),\n",
    "                  index=vectorizer.get_feature_names_out(),\n",
    "                  columns=[n for n in documents])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "3wR8NW3PEiTa",
    "outputId": "52e36b15-f47b-4d71-a15c-1c0674fc377b"
   },
   "source": [
    "# Term-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    if isinstance(text, list):\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "    for char in \"\"\"1234567890.,:;!?()~*\\-\"'\\n\"\"\":\n",
    "        text = text.replace(char,\" \")\n",
    "    \n",
    "    text = text.lower().split()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def term_term_matrix(documents, window_size):\n",
    "    \n",
    "    d = defaultdict(int)\n",
    "    V = set()\n",
    "    \n",
    "    text = tokenize(documents)\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        token = text[i]\n",
    "        V.add(token)\n",
    "        next_token = text[i+1 : i+1+window_size]\n",
    "        for t in next_token:\n",
    "            key = tuple(sorted([t,token]))\n",
    "            d[key] += 1\n",
    "    \n",
    "    V = sorted(V)\n",
    "    df = pd.DataFrame(data=np.zeros((len(V), len(V)), dtype=np.int16),\n",
    "                      index=V,\n",
    "                      columns=V)\n",
    "    \n",
    "    for key, value in d.items():\n",
    "        df.at[key[0], key[1]] = value\n",
    "        df.at[key[1], key[0]] = value\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This is the first document.\",\n",
    "             \"This document is the second document.\",\n",
    "             \"And this is the third one.\",\n",
    "             \"Is this the first document?\"]\n",
    "\n",
    "term_term_matrix(documents, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bible = open(\"bible.txt\").read()\n",
    "\n",
    "df = term_term_matrix(bible, 4)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "god = df[\"god\"]/norm(df[\"god\" ])\n",
    "glory = df[\"glory\"]/norm(df[\"glory\"])\n",
    "slave = df[\"slave\"]/norm(df[\"slave\"])\n",
    "devil = df[\"devil\"]/norm(df[\"devil\"])\n",
    "\n",
    "print(god @ glory)\n",
    "print(god @ slave)\n",
    "print(god @ devil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This is the first document.\",\n",
    "             \"This document is the second document.\",\n",
    "             \"And this is the third one.\",\n",
    "             \"Is this the first document?\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "df = pd.DataFrame(X.T.todense(),\n",
    "                  index=vectorizer.get_feature_names_out(),\n",
    "                  columns=[n for n in documents])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [open(\"harrypotter1.txt\").read(),\n",
    "             open(\"harrypotter3.txt\").read(),\n",
    "             open(\"bible.txt\").read()]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "df = pd.DataFrame(X.T.todense(),\n",
    "                  index=[vectorizer.get_feature_names_out()],\n",
    "                  columns=[\"HP 1\", \"HP 3\", \"Bible\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"HP 1\"] @ df[\"HP 3\"]/(norm(df[\"HP 1\"])*norm(df[\"HP 3\"])))\n",
    "print(df[\"HP 1\"] @ df[\"Bible\"]/(norm(df[\"HP 1\"])*norm(df[\"Bible\"])))\n",
    "print(df[\"HP 3\"] @ df[\"Bible\"]/(norm(df[\"HP 3\"])*norm(df[\"Bible\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Pointwise Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPMI(df,alpha=1):\n",
    "    pij = df/df.sum().sum()\n",
    "    pi  = np.sum(df.to_numpy(),axis=1)/df.sum().sum()\n",
    "    pj  = np.sum(df.to_numpy(),axis=0)**alpha/(df.sum()**alpha).sum()\n",
    "    A = np.log2(pij/(pi.reshape(pi.shape[0],1) @ pj.reshape(1,pj.shape[0])))\n",
    "    #A[A<0] = 0\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This is the first document.\",\n",
    "             \"This document is the second document.\",\n",
    "             \"And this is the third one.\",\n",
    "             \"Is this the first document?\"]\n",
    "\n",
    "PPMI(term_term_matrix(documents, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobi\\anaconda3\\envs\\new\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.943335</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.943335</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389136</td>\n",
       "      <td>0.472342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242896</td>\n",
       "      <td>0.694735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.358373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.135981</td>\n",
       "      <td>0.445613</td>\n",
       "      <td>0.282221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135981</td>\n",
       "      <td>0.135981</td>\n",
       "      <td>0.102392</td>\n",
       "      <td>0.135981</td>\n",
       "      <td>0.141743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504614</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.943335</td>\n",
       "      <td>0.627170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.943335</td>\n",
       "      <td>0.668006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.135981</td>\n",
       "      <td>0.668006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102392</td>\n",
       "      <td>0.135981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135981</td>\n",
       "      <td>0.627170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third</th>\n",
       "      <td>0.943335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.943335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235046</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.154860</td>\n",
       "      <td>0.188448</td>\n",
       "      <td>0.188448</td>\n",
       "      <td>0.640287</td>\n",
       "      <td>0.188448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               and  document     first        is       one    second  \\\n",
       "and       0.000000  0.000000  0.000000  0.587819  0.000000  0.943335   \n",
       "document  0.000000  0.000000  0.389136  0.472342  0.000000  0.242896   \n",
       "first     0.000000  0.668006  0.000000  0.587819  0.358373  0.000000   \n",
       "is        0.135981  0.445613  0.282221  0.000000  0.135981  0.135981   \n",
       "one       0.000000  0.000000  0.504614  0.587819  0.000000  0.000000   \n",
       "second    0.943335  0.668006  0.000000  0.587819  0.000000  0.000000   \n",
       "the       0.135981  0.668006  0.000000  0.102392  0.135981  0.000000   \n",
       "third     0.943335  0.000000  0.000000  0.587819  0.943335  0.000000   \n",
       "this      0.000000  0.235046  0.334689  0.154860  0.188448  0.188448   \n",
       "\n",
       "               the     third      this  \n",
       "and       0.587819  0.943335  0.000000  \n",
       "document  0.694735  0.000000  0.248658  \n",
       "first     0.002857  0.000000  0.627170  \n",
       "is        0.102392  0.135981  0.141743  \n",
       "one       0.587819  0.943335  0.627170  \n",
       "second    0.000000  0.000000  0.627170  \n",
       "the       0.000000  0.135981  0.627170  \n",
       "third     0.587819  0.000000  0.627170  \n",
       "this      0.640287  0.188448  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMI(term_term_matrix(documents, 4),alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobi\\anaconda3\\envs\\new\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "text = open(\"harrypotter1.txt\").read()\n",
    "ppmi = PPMI(term_term_matrix(text, 4),alpha=0.75)\n",
    "cosine = np.zeros(len(ppmi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fred : 0.9999999999999999\n",
      "george : 0.44162828783040325\n",
      "weasley : 0.25733323660990437\n",
      "misters : 0.23413829925206553\n",
      "party : 0.1799598040111192\n",
      "prefect : 0.1732174028120061\n",
      "responsible : 0.17117505499384783\n",
      "mere : 0.17102011235897505\n",
      "oliver : 0.16714629752360366\n",
      "chase : 0.16573116102229024\n"
     ]
    }
   ],
   "source": [
    "target = \"fred\"\n",
    "for i,word in enumerate(ppmi.index):\n",
    "    cosine[i] = ppmi.loc[target] @ ppmi.loc[word]/(norm(ppmi.loc[target])*norm(ppmi.loc[word]))\n",
    "\n",
    "for i in np.argsort(cosine)[-10:][::-1]:\n",
    "    print(ppmi.index[i],\":\",cosine[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobi\\anaconda3\\envs\\new\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:402: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.024513</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.053175</td>\n",
       "      <td>0.029953</td>\n",
       "      <td>-0.067987</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>-0.001711</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015731</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.011897</td>\n",
       "      <td>-0.015370</td>\n",
       "      <td>-0.012497</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>-0.003935</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.014117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaaaargh</th>\n",
       "      <td>-0.006467</td>\n",
       "      <td>-0.007308</td>\n",
       "      <td>-0.004428</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>-0.016272</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>-0.011797</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>-0.006075</td>\n",
       "      <td>-0.013140</td>\n",
       "      <td>-0.004045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaargh</th>\n",
       "      <td>-0.005044</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>-0.001799</td>\n",
       "      <td>-0.017806</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>-0.005613</td>\n",
       "      <td>0.011318</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.011171</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>-0.003620</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>-0.007508</td>\n",
       "      <td>-0.013993</td>\n",
       "      <td>-0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaah</th>\n",
       "      <td>-0.003107</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.004086</td>\n",
       "      <td>-0.002184</td>\n",
       "      <td>-0.002632</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>-0.008891</td>\n",
       "      <td>-0.001784</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017995</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>-0.004634</td>\n",
       "      <td>-0.002292</td>\n",
       "      <td>-0.012402</td>\n",
       "      <td>-0.021749</td>\n",
       "      <td>-0.034486</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>-0.029446</td>\n",
       "      <td>0.006735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aargh</th>\n",
       "      <td>-0.008412</td>\n",
       "      <td>-0.007081</td>\n",
       "      <td>-0.012034</td>\n",
       "      <td>-0.012007</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.021455</td>\n",
       "      <td>-0.006598</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>-0.012125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>-0.007075</td>\n",
       "      <td>-0.008577</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>-0.007009</td>\n",
       "      <td>-0.001453</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>-0.010668</td>\n",
       "      <td>-0.012984</td>\n",
       "      <td>-0.010473</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.023759</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.017075</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.035160</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>-0.016196</td>\n",
       "      <td>-0.005896</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-0.004352</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>-0.002830</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>-0.019821</td>\n",
       "      <td>0.013153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>-0.009724</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>-0.016376</td>\n",
       "      <td>-0.011147</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>-0.033980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>-0.006122</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.006782</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008257</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>-0.007289</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>-0.004071</td>\n",
       "      <td>-0.004469</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>-0.002568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoomed</th>\n",
       "      <td>-0.008075</td>\n",
       "      <td>-0.019652</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>-0.003357</td>\n",
       "      <td>0.018906</td>\n",
       "      <td>-0.009339</td>\n",
       "      <td>-0.010859</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>-0.017905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004394</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>-0.004060</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>-0.002502</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.011093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooming</th>\n",
       "      <td>-0.009319</td>\n",
       "      <td>-0.016953</td>\n",
       "      <td>-0.001106</td>\n",
       "      <td>-0.001034</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.015189</td>\n",
       "      <td>-0.003862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021629</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>-0.021367</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>-0.007691</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.002884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5764 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5    \\\n",
       "a             -0.024513 -0.002009  0.053175  0.029953 -0.067987  0.000886   \n",
       "aaaaaaaaaargh -0.006467 -0.007308 -0.004428  0.003676 -0.016272 -0.000561   \n",
       "aaaargh       -0.005044 -0.001409 -0.001799 -0.017806 -0.001677 -0.005613   \n",
       "aaah          -0.003107  0.003959 -0.004221 -0.004086 -0.002184 -0.002632   \n",
       "aargh         -0.008412 -0.007081 -0.012034 -0.012007  0.007467  0.006550   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "zombie        -0.010668 -0.012984 -0.010473  0.008511  0.008265  0.000282   \n",
       "zoo           -0.016196 -0.005896 -0.005843 -0.004352  0.009394  0.011178   \n",
       "zoom          -0.006122 -0.004927 -0.001071 -0.006782  0.005180  0.004628   \n",
       "zoomed        -0.008075 -0.019652  0.002937 -0.003357  0.018906 -0.009339   \n",
       "zooming       -0.009319 -0.016953 -0.001106 -0.001034  0.012373  0.005248   \n",
       "\n",
       "                    6         7         8         9    ...       190  \\\n",
       "a             -0.001711  0.009179  0.007623 -0.000178  ... -0.015731   \n",
       "aaaaaaaaaargh  0.002014  0.013575  0.002206 -0.001904  ...  0.017097   \n",
       "aaaargh        0.011318  0.007801  0.011171  0.000204  ...  0.011257   \n",
       "aaah           0.003947 -0.008891 -0.001784  0.001551  ... -0.017995   \n",
       "aargh          0.021455 -0.006598 -0.001580 -0.012125  ... -0.001520   \n",
       "...                 ...       ...       ...       ...  ...       ...   \n",
       "zombie        -0.023759  0.008861  0.017075  0.008577  ...  0.003949   \n",
       "zoo           -0.002830  0.001623 -0.019821  0.013153  ...  0.007291   \n",
       "zoom           0.020436  0.010169  0.005768 -0.002991  ... -0.008257   \n",
       "zoomed        -0.010859  0.004267  0.001732 -0.017905  ... -0.004394   \n",
       "zooming        0.009500 -0.028331  0.015189 -0.003862  ... -0.021629   \n",
       "\n",
       "                    191       192       193       194       195       196  \\\n",
       "a              0.024517  0.011897 -0.015370 -0.012497  0.009113  0.008741   \n",
       "aaaaaaaaaargh -0.011797  0.013328 -0.001343  0.001773  0.014691  0.008925   \n",
       "aaaargh        0.002292 -0.003620  0.010465 -0.002174  0.016402  0.008784   \n",
       "aaah           0.024705 -0.004634 -0.002292 -0.012402 -0.021749 -0.034486   \n",
       "aargh          0.006101 -0.000880 -0.007075 -0.008577 -0.014793  0.015152   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "zombie         0.009656  0.009043  0.010214  0.035160  0.008141  0.002263   \n",
       "zoo            0.016538 -0.009724  0.013578  0.003233 -0.016376 -0.011147   \n",
       "zoom          -0.009619  0.008511 -0.007289  0.006009  0.000276 -0.004071   \n",
       "zoomed        -0.008420  0.002378  0.009651 -0.004060  0.005364 -0.002502   \n",
       "zooming        0.007770  0.015520  0.009845  0.010675 -0.021367  0.006172   \n",
       "\n",
       "                    197       198       199  \n",
       "a             -0.003935  0.001203  0.014117  \n",
       "aaaaaaaaaargh -0.006075 -0.013140 -0.004045  \n",
       "aaaargh       -0.007508 -0.013993 -0.000825  \n",
       "aaah           0.005221 -0.029446  0.006735  \n",
       "aargh         -0.007009 -0.001453  0.002674  \n",
       "...                 ...       ...       ...  \n",
       "zombie        -0.001989 -0.000343 -0.001825  \n",
       "zoo            0.015449  0.002270 -0.033980  \n",
       "zoom          -0.004469  0.009864 -0.002568  \n",
       "zoomed        -0.000765  0.004880  0.011093  \n",
       "zooming       -0.007691 -0.004830 -0.002884  \n",
       "\n",
       "[5764 rows x 200 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(\"harrypotter1.txt\").read()\n",
    "ppmi = PPMI(term_term_matrix(text, 4),alpha=0.75)\n",
    "\n",
    "V,S,D = np.linalg.svd(ppmi.to_numpy())\n",
    "\n",
    "K = 200\n",
    "df = pd.DataFrame(data=V[:,:K],\n",
    "                  index=ppmi.index)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fred : 1.0000000000000002\n",
      "george : 0.8147000895756878\n",
      "misters : 0.676451414136882\n",
      "chase : 0.6188418461492329\n",
      "weasley : 0.5794638326579802\n",
      "party : 0.49461908258651904\n",
      "bounded : 0.48968289427468004\n",
      "tripe : 0.4580777913311184\n",
      "ourselves : 0.4561894266632011\n",
      "jokes : 0.4526611098833193\n"
     ]
    }
   ],
   "source": [
    "cosine = np.zeros(len(df))\n",
    "\n",
    "target = \"fred\"\n",
    "for i,word in enumerate(df.index):\n",
    "    cosine[i] = df.loc[target] @ df.loc[word]/(norm(df.loc[target])*norm(df.loc[word]))\n",
    "\n",
    "for i in np.argsort(cosine)[-10:][::-1]:\n",
    "    print(df.index[i],\":\",cosine[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
